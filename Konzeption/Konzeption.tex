\section{\acf{MFEM}}

Die Bewertung, ob ein Framework für den produktiven Einsatz in einer Microservice Architektur geeignet ist, lässt sich nicht auf die Servicearchitektur beschränken. Aus diesem Grund ist \ac{MFEM} keine reine Architekturbewertungs-Methode. Sie betrachtet einerseits die durch das Framework vorgegebene Servicearchitektur und versucht dabei Risiken aufzudecken sowie ein tieferes Verständnis für die Architektur zu schaffen. Auf der anderen Seite wird das Framework als Produkt aufgefasst und versucht, eine Aussage über die Qualität dessen zu treffen. \ac{MFEM} setzt dabei keine grundlegenden Kenntnisse über das Framework voraus, da es 2 Seiten der Analyse anbietet. Dies ist einerseits die Nutzung von bereits vorhandenem Expertenwissen, was die Phase der Evaluation verkürzt. Andererseits werden die restlichen Daten über die Erstellung von Prototypen erfasst.
Auf dieser Basis kann am Ende eine begründete Entscheidung für oder gegen den Einsatz eines Frameworks getroffen werden.

Der Ablauf von \ac{MFEM} ist in Bild \ref{MFEMAblauf} schematisch dargestellt und startet mit der optionalen Kickoff-Phase. Diese kann somit auch übersprungen werden, wenn die beteiligten Personen nur die Software-Architekten selbst sind. Sollten bei der Bewertung auch weitere Stakeholder mit einbezogen werden, wird zur Durchführung der Kickoff-Phase geraten.

\image[MFEM-Phasen.pdf][width=0.75\linewidth]{MFEMAblauf}{Ablaufschema MFEM}{Schematische Darstellung vom Ablauf von \ac{MFEM}}

\subsection{Kickoff-Phase}

In der Kickoff Phase geht es darum, Klarheit zu schaffen. Den Beteiligten Personen sollten der Ablauf und die Ziele dieser Methode erläutert werden. Wie auch schon bei \ac{ATAM} ist das Ziel von \ac{MFEM} nicht die Vergabe von Noten. Vielmehr geht es darum den Reifegrad eines Frameworks und etwaige Risiken, wie erhöhten Entwicklungsaufwand für fehlende Funktionen, festzustellen. 

In diesem Zusammenhang sollte auch die vorhandene Microservice Architektur vom Software-Architekten vorgestellt werden, damit die Grundlage der Bewertung klar ist. Neben den in der Architektur getroffenen Entscheidungen geht es auch um technische Einschränkungen und Abhängigkeiten zu Drittsystemen. Auf dieser Basis kann die Architektur analysiert und Anforderungen definiert werden.

\subsection{Analysephase}

\image[MFEM-Analysephase.pdf][width=0.4\linewidth]{MFEM-Analysephase}{MFEM-Analysephase}{Analysephase von \ac{MFEM}}

\subsubsection{Architektur Analyse und Wahl der Anforderungen}\label{Analyse_Wahl_Anforderungen}

Aus dem vorangegangenen Kapitel wird ersichtlich, dass eine Bewertung nicht nur frühzeitig erfolgen muss. Viel mehr ist es wichtig, dass diese auch auf detaillierten Anforderungen basiert. Durch die maßgeblichen Stakeholder werden diese vorgegeben. In einer Microservice Architektur sind dies die definierten Umstände eines Services. Diese beschränken sich dabei nicht auf die Kommunikation zwischen zwei einzelnen Services. Gerade die Komposition der Microservices über die Infrastruktur muss gewährleistet sein. Wobei Punkte wie Sicherheit und Wartbarkeit die Komplexität noch steigern.
Damit ein Service dies erfüllt und somit in der Architektur funktionieren kann, müssen anhand der Umstände, wie z.~B. Servicediscovery, Logging oder Tracing, Anforderungen definiert werden. Nur wenn das Framework eines Services diese unterstützt, kann garantiert werden, dass es in die Gesamtarchitektur passt.

\newparagraph{Funktionale Serviceanforderungen}
\
Es müssen demnach Anforderungen gefunden werden, die die Microservice Architektur an die einzelnen Services stellt. Das ist dabei stark von der Umsetzung dieser abhängig. Ein gutes Beispiel hierfür ist die Servicediscovery. Dass sich Services gegenseitig finden können, ohne die Flexibilität der Architektur zu verlieren, darf eben diese nicht fehlen. Die Umsetzung kann dabei jedoch stark variieren. So kann ein zentraler Service, wie z.~B. Netflix-Eureka\footnote{
\url{https://github.com/Netflix/eureka}
}
oder Consul\footnote{
\url{https://www.consul.io}
}
, eine Registrierungsstelle anbieten. Dort können sich sämtliche Service-Instanzen registrieren und auch andere Services finden. Diese müssen es aber auch nicht direkt unterstützen. Projekte wie Spring Cloud Sidecar\footnote{
\url{http://projects.spring.io/spring-cloud/spring-cloud.html\#_polyglot_support_with_sidecar}
}
übernehmen dies für einzelne Services. Die Discovery kann aber auch auf die darüber liegende Abstraktions-Schicht hochgezogen werden. Innerhalb eines Kubernetes\footnote{
\url{http://kubernetes.io}
}
Clusters übernimmt die Service-Verwaltung diese Aufgabe selbst und stellt sie über Umgebungsvariablen oder DNS zur Verfügung. 

\image[Servicediscoverytypen.pdf]{Servicediscoverytypen}{Servicediscovery Typen}{Beispiele für Ausprägungen der Servicediscovery}

Die spezifische Ausprägung der Architektur gibt somit Anforderungen vor, die es zu identifizieren gilt. Diese stellen die funktionalen Serviceanforderungen dar und müssen für die Akzeptanz erfüllt werden. Sollte sich mit einem Framework z.~B. nicht die benötigte Authentifizierung umsetzen lassen, kann der Service nicht vor Missbrauch geschützt werden. Ein Einsatz im produktiven Umfeld wäre demnach undenkbar oder nur mit unverhältnismäßig großem Aufwand zu realisieren.

\newparagraph{Nicht-Funktionale Serviceanforderungen}
\
Neben den funktionalen Serviceanforderungen lassen sich auch nicht-funktionale Anforderungen definieren, die zur Erreichung und Zufriedenstellung der benötigen Funktionen notwendig sind. Dies muss dabei nicht auf die durch das Framework vorgegebene Architektur des Services beschränkt sein. An dieser Stelle kann das Framework als Werkzeug aufgefasst werden. Es gilt somit nicht nur die Frage zu klären, ob ein Framework eine benötigte Funktion bereitstellt. Sondern ob es den Entwickler bei der Umsetzung bestmöglich unterstützt und dabei flexibel bleibt. Nach dem KISS-Prinzip\footnote{
\url{http://principles-wiki.net/principles:keep_it_simple_stupid}
} 
wird zum Beispiel die Funktion bevorzugt, die möglichst einfach und \enquote{dumm} erscheint. So brauch es für die Umsetzung keine anspruchsvollen oder besonders cleveren Lösungen. Eine Einfache lässt sich nicht nur besser Lesen und Verstehen, es erhöht auch die Wartbarkeit.  

\newparagraph{Basisanforderungen von \ac{MFEM}}
\
Damit das Bewertungsteam, bei der Findung von funktionalen und nicht-funktionalen Serviceanforderungen, nicht bei null anfangen muss, wird an dieser Stelle eine Orientierungshilfe angeboten. Hier wurde in einem Brainstorming versucht, eine Schnittmenge an Anforderungen zu finden, die für die meisten Microservice Architekturen gelten sollte. 
Die so gefundenen Anforderungen basieren auf der Erfahrung der Anwendungsentwicklung innerhalb der Landeshauptstadt München. Diese hat sich in den letzten Jahren mit dem produktiven Einsatz von Microservices beschäftigt und diverse erfolgreiche Projekte damit umgesetzt.\todo{anders Formulieren und ausschmücken}   

Um die Analyse und Wahl der Anforderungen zu unterstützen, wird hier ein Quality Utility Tree aufgebaut.

\newparagraph{Entwicklung Quality Utility Tree}
\todoInline{Priorisierung von Anforderungen}

Der Quality Utility Tree bietet einen effizienten Top-Down Ansatz zur Identifizierung und Verfeinerung von Qualitätsanforderungen. Die mittels Brainstorming gefundenen Anforderungen werden in einzelne Kategorien aufgeteilt und bis zu den konkreten Zielen weiter verfeinert. Bei der Kategorisierung kann das Qualitätsmodell aus der ISO/IEC 25010 hergenommen werden. Wobei das Modell nur eine Hilfestellung ist und keine Vorgabe darstellt. Hier wurden die Kategorien Funktionalität, Performance, Benutzbarkeit, Sicherheit und Wartbarkeit definiert. Anschließend wurden diesen die Qualitätsanforderungen zugeordnet. Bild \ref{MSQUTAusschnitt} zeigt einen Ausschnitt des gesamten Baumes, wobei der vollständige Baum im Anhang zu finden ist. 

\image[MSQUTAusschnitt.pdf][width=0.7\linewidth]{MSQUTAusschnitt}{\acs{MFEM} Quality Utility Tree Beispiel}{Ausschnitt aus dem Quality Utility Tree der Basisanforderungen}

\subsubsection{Metriken definieren über \ac{GQM}}\todo{Ausführlicher Ablauf erklären}

Für die identifizierten Qualitätsanforderungen müssen möglichst aussagekräftig Metriken gefunden werden. Dies können dabei Messung an der Architektur sein, wie das Vorhandensein spezifischer Funktionen oder Komponenten sowie den Einsatz bewährter Entwurfsmuster. Dabei können die möglichen Ergebnisse komplexer als nur ein einfaches \enquote{enthalten} oder \enquote{nicht enthalten} sein. Falls beispielsweise eine spezifische Funktion vom Framework nicht unterstützt wird, heißt dies nicht, dass sich diese nicht umsetzen lässt. Hier bietet sich eine Ordinalskala an. Wobei folgende mögliche Ergebnisse verwendet werden können: enthalten, leicht umsetzbar, schwer umsetzbar, nicht möglich. Dieser Ansatz bietet den Vorteil, dass das Ergebnis quantifizierbar ist.
Zusätzlich können auch Softwaremetriken genutzt werden. Da im Zuge der Evaluation ein Prototyp erstellt wird, können an diesem auch direkt Messungen vorgenommen werden. Damit kann neben der Performance auch z.~B. der Aufwand zur Umsetzung bestimmter Funktionen bemessen werden. Falls z.~B. die Erstellung eines \ac{REST}-Endpunktes sehr aufwändig ist und viele Codezeilen sowie Methodenaufrufe benötigt, macht dies den Microservice schnell sehr komplex bei vielen Endpunkten und verschlechtert somit die Wartbarkeit.
Um bei der Definition der Metriken stets das Ziel im Auge zu behalten, wird die bereits bekannte \ac{GQM} Methode genutzt. 

Eine um Metriken erweiterter Qualitätsbaum ist in Bild \ref{MFEMGQMQUTAusschnitt} dargestellt. Wie zuvor ist dies nur ein Ausschnitt, wobei der gesamte Baum im Anhang zu finden ist.

\image[MFEMGQMQUTAusschnitt.pdf]{MFEMGQMQUTAusschnitt}{\acs{MFEM} Qualitätsbaum erweitert um Metriken}{Ein Ausschnitt aus dem Qualitätsbaum erweitert um Metriken}

\subsection{Evaluationsphase}

\image[MFEM-Evaluationsphase.pdf][width=0.4\linewidth]{MFEM-Evaluationsphase}{MFEM-Evaluationsphase}{Evaluationsphase von \ac{MFEM}}

Während der Evaluation wird das Framework auf die Anforderungen mittels der zuvor definierten Metriken untersucht. Dabei wird ein tieferer Blick in das Framework geworfen. Neben der Untersuchung von Dokumentation und bereits vorhandenem Expertenwissen, wird auch ein Prototyp erstellt. Dieser soll als Referenz für zukünftig entwickelte Services gelten und muss somit zielgerichtet entwickelt werden. Es gilt in kürzester Zeit essenzielle Funktionen umzusetzen und dabei Erkenntnisse über das Framework zu gewinnen. Um dies zu Unterstützen muss im ersten Schritt die Evaluation genauer definiert werden.

\subsubsection{Evaluation definieren}\label{Evaluation_definieren}

In der Softwareevaluation wird zwischen der subjektiven und objektiven Evaluation unterschieden\cite{Hegner2016}.
Dabei versucht die subjektive Evaluation eine Beurteilung durch den Benutzer zu finden, wobei der Benutzer im Fall von \ac{MFEM} der Softwareentwickler ist. Während dieser Evaluation werden sogenannte \enquote{weiche} Daten erhoben. Diese sagen aus, ob die Entwicklung mit dem Framework effizient, einfach, klar oder einsichtig ist. Es wird somit versucht eine Aussage über die Akzeptanz zu treffen.
Die subjektiven Eindrücke versucht man bei der objektiven Evaluation möglichst auszuschalten. Das gelingt durch das Anwenden von \enquote{harten} Methoden zur Erhebung von quantitativer, statisch abgesicherter Daten\cite{Hegner2016}. Sehr gute Beispiele hierfür sind Performancemessungen, Fehlerraten oder Komplexitätsbestimmungen.  

\newparagraph{Subjektive Evaluation}
\
Während der subjektiven Evaluation soll bei \ac{MFEM} der Prototyp von einem Experten erstellt werden. Wie eingangs erwähnt muss dies zielgerichtet ablaufen. Um dies zu unterstützen und gleichzeitig eine Aussage über Qualitätsmerkmale wie Lernbarkeit, Analysierbarkeit, Wartbarkeit oder Benutzbarkeit zu treffen, soll der \ac{CW} verwendet werden. Dies ist eine aufgabenorientierte Inspektionsmethode\cite{Hegner2016}. Dabei versetzt sich der Prüfer in einen hypothetischen Benutzer und analysiert konkrete Handlungsabläufe. Dies kann z.~B. das Lösen eines Problems oder das Umsetzen einer einfachen Funktion sein. 
So kann er feststellen, woran die Entwicklung eines Microservices mit Hilfe des Frameworks vermutlich scheitern wird.

Der \ac{CW} verläuft in 3 Schritten\cite{Hegner2016}:

\begin{description}[leftmargin=!,labelwidth=\widthof{\bfseries Input definieren}]
	\item[1. Vorbereitung]
	In diesem Schritt werden die Beispielszenarien definiert. D.~h. es werden für den Experten Aufgaben bzw. Problemstellungen festgelegt, die durchgeführt oder gelöst werden sollen. Dies können grundlegend Aufgaben sein, wie das Erstellen eines \ac{REST}-Endpunktes. Sie sollten so präzise wie möglich formuliert werden.
	\item[2. Analyse]
	Während der Analyse nimmt sich der Experte ein Szenario nach dem anderen zur Hand und führt dieses durch. Für jede Aktivität wird ein Protokoll angefertigt. Durchgeführten Aktionen und damit eventuell zusammenhängenden Probleme oder Feststellungen sind damit festzuhalten.
	\item[3. Follow Up]
	Die durch die Analyse gewonnenen Erkenntnisse werden zusammengefasst und ausgewertet. Falls nötig, können Maßnahmen bestimmt werden.
\end{description}

Der Vorteil des \ac{CW} ist die schnelle und einfache Anwendung. Zudem kann es, wie von \ac{MFEM} benötigt, in einem frühen Stadium der Entwicklung verwendet werden.\cite{Wharton1994} 
Im derzeitigen Definitionsschritt müssen in erster Linie Szenarien definiert werden. Die Analyse und das Follow Up erfolgen in den nächsten Schritten.

\newsubparagraph{Definition von Szenarien}\label{Definition_Szenarien}

Für die Definition der Szenarien muss ein Standard-Anwendungsfall gefunden werden. Hierzu sollten sich die Prüfer überlegen, wie ein herkömmlicher Service, der mit dem Framework erstellt werden soll, aussehen könnte und was dieser für Eigenschaften haben sollte. Da der Einsatzzweck stark an die zuvor definierten Anforderungen gebunden ist, können diese für die Definition genutzt werden. Soll der Service z.~B. eine eigene Datenbank verwalten und diese mittels \ac{REST} nach außen anbieten oder wird Event Sourcing eingesetzt? Vielleicht soll der Service aber auch keine eigenen Daten verwalten, sondern diese von anderen Services einholen und zusammenführen.

Die Definition des Standard-Anwendungsfalls kann erst einmal grob erfolgen und wird im Folgenden weiter verfeinert. Hierzu sollte der gefundene Anwendungsfall in Entwicklungsstufen aufgeteilt werden. Diese stellen anschließend die Szenarien dar. Die Anzahl sollte dabei gering gehalten werden (z.~B. 3 Szenarien), damit der Evaluationsaufwand nicht zu groß wird. Um die Szenarien weiter zu verfeinern und einen Rückschluss auf die Anforderungen zu gewährleisten, werden anschließend den Szenarien die zu messenden Metriken zugeordnet. Dabei kann es vorkommen, dass sich einzelne Metriken nicht zuordnen lassen, da die Szenarien anfangs nur grob definiert sind. In diesem Fall müssen die Szenarien in Hinblick auf die fehlenden Metriken weiter verfeinert werden. Der dadurch entstehende Kreislauf ist im Bild \ref{MFEM-Evaluationskreislauf} abgebildet.       

\image[MFEM-Evaluationskreislauf.pdf][width=0.5\linewidth]{MFEM-Evaluationskreislauf}{MFEM Kreislauf Evaluation}{Kreislauf zur Definition und Verfeinerung der Szenarien}

Bei der Zuordnung der Metriken muss zwischen objektiver und subjektiver Evaluation unterschieden werden. Aus diesem Grund wird dieser Vorgang erst im Abschnitt \ref{Metriken_zuordnen} genauer erläutert, nachdem auch die objektive Evaluation definiert wurde.

\newsubparagraph{Beispiel-Szenarien}

Im Folgenden werden 3 Beispiel-Szenarien definiert, die den Anwendungsfall eines einfachen Daten-Service darstellen sollen. Dieser hat eine Anbindung an eine Datenbank und stellt das enthaltene Datenmodell mittels \ac{REST} zur Verfügung. Mit dieser groben Definition werden die 3 Szenarien gebildet.

\textbf{Szenario 1 Installation:} Die Grundlage für den Einsatz eines Frameworks ist die Installation der benötigten Komponenten. Da \ac{MFEM} sprachunabhängig ist, kann nicht davon ausgegangen werden, dass alle beteiligten Entwickler bereits die benötigen Compiler bzw. Interpreter und zugehörige Bibliotheken installiert haben. Zudem werden in Zeiten von Continuous Integration\footnote{\url{https://de.wikipedia.org/wiki/Kontinuierliche_Integration}} und immer kürzer werdenden Time-to-Market Zyklen automatische Build-Tools benötigt. Die Einrichtung dieser Komponenten ist somit die Basis einer jeden Entwicklung und stellt das erste Szenario dar.

\image[Szenario1.pdf][width=0.5\linewidth]{Installation}{Installation eines Frameworks}{Szenario 1: Installation des Frameworks mit allen benötigten Komponenten.}

\textbf{Szenario 2 einfacher Service:} Die ersten Schritte, gerade in einem ungewohnten Umfeld, sollten nicht zu groß gewählt werden, damit ein erster Eindruck zur Struktur und Syntax erfolgen kann. So bildet das zweite Szenario die Erstellung eines einfachen Hello-World-Services. Dieser soll einen Endpunkt enthalten, der auf jegliche Anfrage \enquote{HELLO World!} antwortet. Als Ergebnis werden so erste Erkenntnisse über die Funktionsweise des Frameworks und der Erstellung von grundlegenden Elementen eines Microservices gewonnen. Da die Absicherung des Services ein wesentlicher Bestandteil ist, soll anschließend der Endpunkt mit einer Authentifizierung abgesichert werden. Die genaue Umsetzung hängt dabei von den zuvor definierten Anforderungen ab. 
Mit den Basis-Anforderungen von \ac{MFEM} wird eine Authentifizierung mittels OAuth2-Token gefordert. Zur Vereinfachung werden \ac{JWT}\footnote{\url{https://jwt.io}} eingesetzt, da diese signiert sind und vom Service, ohne weitere Kommunikation mit anderen Services, selbst validiert werden können.   

\image[Szenario2.pdf][width=0.6\linewidth]{EinfacherService}{Einfacher Service}{Szenario 2: Erstellung eines einfachen Hello-World-Services.} 

\textbf{Szenario 3 erweiterter Service:} Das dritte Szenario baut auf dem zweiten auf und erweitert es um ein Datenmodell. Hier soll neben der Anbindung an eine Datenbank auch die Erstellung einer komplexeren API durchgeführt werden. Das Modell muss dabei als solches nicht komplex sein. Hier wird eine einfach Personal- und Aufgabenverwaltung umgesetzt. Dieses teilt Mitarbeiter in Abteilungen auf, welche wiederum Mitarbeiter als Abteilungsleiter haben. Zusätzlich können Mitarbeitern Aufgaben zugeordnet werden. Das vollständige Datenmodell ist im Bild \ref{ErweiterterService} dargestellt.

\image[Szenario3Datenmodell.pdf][width=0.7\linewidth]{Datenmodell}{Datenmodell}{Szenario 3: Datenmodell der Aufgabenverwaltung}

Auf diesem Modell soll auch eine einfache Geschäftslogik implementiert werden, wie die Auflistung aller offenen Aufgaben nach Abteilungen. Die tatsächliche Geschäftslogik spielt dabei weniger eine Rolle. Viel mehr soll der Umgang mit Datenmodell und eigener Logik erprobt werden.

\image[Szenario3.pdf][width=0.7\linewidth]{ErweiterterService}{Service mit Datenmodell}{Szenario 3: Erstellung eines erweiterten Services.}
	
\newparagraph{Objektive Evaluation}
\
Die objektive Evaluation dient zur Findung der \textbf{harten} Daten. Hierzu werden die Artefakte aus der subjektiven Evaluation als Grundlage der Messungen genutzt. So können einzelne Funktionen im Code auf Komplexität untersucht werden, damit z.~B. eine Aussage über Umsetzungsaufwand oder Wartbarkeit getroffen werden kann. Neben diesen Messungen direkt an den Artefakten kann auch eine Performance Messung und Recherche zur Ermittlung der harten Daten herangezogen werden. 

\newsubparagraph{Performance Messung}
Der aus der subjektiven Evaluation gewonnene lauffähige Prototyp kann für Performance-Messungen herangezogen werden. Hierzu sollen ein oder mehrere Anforderungsprofile definiert werden, die eine reguläre Nutzung des Services unter verschiedenen Situationen betrachtet. Damit werden die Voraussetzungen und Umstände für die Messungen genauer definiert. 

\begin{table}[!h]
	\centering
	\begin{tabular}{p{1cm}p{4cm}p{2cm}p{2cm}p{4cm}}
		\textbf{Nr.} & \textbf{Name} & \textbf{parallele Anfragen} & 
		\textbf{Wieder- holungen} & \textbf{Besonderheit} \\
		\hline
		1 	& Datenservice 			& 255	&	500		& CRUD Operationen auf Datenbank  \\
		\hline
		2	& Einfacher Service		& 255 	&	500		& Wenig rechenintensive Geschäftslogik   \\
		\hline
		3	& Komplexer Service 	& 255	&	500		& Stark rechenintensive Geschäftslogik  \\
		\hline
	\end{tabular}
	\caption[Anforderungsprofile]{Beispiel: Anforderungsprofile für die objektiven Evaluation am Prototyp}
	\label{Anforderungsprofile}
\end{table}

Das erste Anforderungsprofil stellt einen einfachen Datenservice dar. Dieser ist mit einer Datenbank verbunden und führt diese über die \ac{REST}-Schnittstelle nach außen. Durch die hohen Anfragen wird dieser Service stark unter Last gestellt, um eine Aussage über Qualitätsmerkmale wie Stabilität, Fehlerrate und Durchsatz zu treffen.

Um möglichst limitierende Faktoren, wie die Datenbank, auszuschließen, wurden das Profil zwei definiert. Dieses baut auf einer Geschäftslogik im Service auf. Dabei spielt es keine Rolle, ob ein sinnvolles Ergebnis berechnet wird. Mit der wenig rechenintensiven Logik steht der Overhead des Frameworks im Vordergrund. Ist dieses besonders groß, um z.~B. die übertragenen Daten zu de- und serialisieren, beeinflusst es jede Anfrage am Service und vermindert den Durchsatz. Die stark rechenintensive Logik zielt dabei mehr auf einen Vergleich zu anderen Programmiersprachen ab. Aus diesem Grund sollte die enthaltene Logik einheitlich sein. So kann sie darin bestehen Testdaten zu generieren und diese zu sortieren.

Neben dem reinen Zeitverhalten können an den Profilen noch weitere Messwerte erhoben werden. Dies kann z.~B. Speicherbedarf in Ruhe sowie bei Vollauslastung sein. Dabei stellen die zuvor genannten Punkte nur Beispiele für Messungen an den Profilen dar. Welche genau durchgeführt werden, wurde bereits mit den Anforderungen über \ac{GQM} definiert. So bleiben die tatsächlichen Messungen sinnvoll.

\newsubparagraph{Recherche}
Auch durch eine Recherche können harte Daten gewonnen werden. So lassen sich Fragen beantworten, die in erster Linie nicht direkt mit der Entwicklung eines Microservices zusammenhängen. Bei einem Open-Source-Framework stellt sich z.~B. die Frage, ob dieses eine aktive Entwicklergemeinschaft hat und regelmäßig Fehler behoben werden. Sollte z.~B. die Behebung eines Fehlers viel Zeit in Anspruch nehmen, kann dies im produktiven Umfeld schnell zu Problemen führen. Auch ein kommerzieller Support kann gewünscht sein, wenn eigenes Fachwissen fehlt oder tiefgreifende Fehler schnell behoben werden sollen. Solche Punkte sind häufig mit ausschlaggebend bei der Entscheidung für ein Framework und sollten mit berücksichtigt werden.

\subsubsection{Metriken zuordnen}\label{Metriken_zuordnen}

Die in der Analysephase gefunden Metriken müssen den genauen Messpunkten zugeordnet werden. Wie in Abschnitt \ref{Evaluation_definieren} definiert, wird die Evaluation in objektiv und subjektiv unterschieden. Aus diesem Grund müssen die Metriken dahingehend differenziert werden. Die Objektiven lassen sich dabei am einfachsten erkennen, da sie harte Daten erheben. Diese können am Prototyp oder durch eine Recherche gewonnen werden.
Die Subjektiven basieren auf der Einschätzung des Prüfers und sollen in den Szenarien der subjektiven Evaluation ermittelt werden. Bild \ref{ZuordnungMetriken} zeigt diese Aufteilung. 

\image[MetrikenZuordnung.pdf][width=0.7\linewidth]{ZuordnungMetriken}{Zuordnung Metriken}{Aufteilung der Metriken in subjektiv und objektiv sowie Zuordnung zu einzelnen Messpunkten}

Wie bereits in Abschnitt \ref{Definition_Szenarien} erwähnt, kann es vorkommen, dass sich einzelne subjektive Metriken nicht zuordnen lassen. In diesem Fall müssen die Szenarien angepasst und verfeinert werden. 

\subsubsection{Evaluation durchführen}

An dieser Stelle werden die zuvor definierten Evaluationsprozesse durchgeführt. Dabei sollte der Fokus auf die Anforderungen mit hoher Priorität stehen. So kann das frühzeitig nicht Erfüllen von wichtigen Anforderungen direkt zum Abbruch führen.

Zu aller erst werden die Szenarien des \ac{CW} umgesetzt. Dabei müssen die gewonnenen Erkenntnisse negativ als auch positiv protokolliert werden, damit diese sich später besser auswerten lassen. Sobald ein Szenario durchgeführt wurde, wird es durch die zugeordneten Metriken bewertet.

Nachdem das letzte Szenario de \ac{CW} durchgeführt wurde, steht ein Prototyp für die objektive Evaluation bereit. An diesem werden nun über den Programmcode die Softwaremetriken gemessen. Zusätzlich wird am laufenden Prototyp mittels Tools, wie z.~B. JMeter\footnote{http://jmeter.apache.org}, die Leistung sowie der Durchsatz gemessen.

\subsection{Abschlussphase}

\image[MFEM-Abschlussphase.pdf][width=0.4\linewidth]{MFEM-Abschlussphase}{MFEM-Abschlussphase}{Abschlussphase von \ac{MFEM}}

In der Abschlussphase geht es um die Aufbereitung und Präsentation der Daten. Die zuvor durchgeführten Phasen bringen viele Anforderungen und zugehörige Metriken hervor. Da dies einen schlechten Überblick über das Gesamtergebnis liefert, werden im nächsten Schritt die Daten aufbereitet.

\subsubsection{Ergebnisse auswerten}

Da Entscheidungsträger häufig keine Zeit für Detailanalysen haben, müssen die Daten so aufbereitet werden, dass mit einem Blick ein Gesamtergebnis sichtbar wird. Detailfragen lassen sich weiterhin durch die Anforderungen und Ergebnisse der Metriken klären. Ein sehr guten Überblick lässt sich durch ein Netzdiagramm erreichen. Hierzu können die Qualitätskategorien aus dem im Abschnitt \ref{Analyse_Wahl_Anforderungen} erstellten Quality Utility Tree für die Achsen genommen werden. Um einen Eindruck für das Ergebnis der Auswertung zu erhalten, ist ein Beispiel in Bild \ref{Netzdiagramm} dargestellt.

\image[Netzdiagramm.pdf][width=0.8\linewidth]{Netzdiagramm}{Netzdiagramm}{Beispiel für aufbereitet Daten als Netzdiagramm mit Qualitätskategorien als Achsen.}  

Die Achsen der einzelnen Qualitätskategorien stellen dabei den Gesamt-Erfüllungsgrad in Prozent dar. Wurden alle Anforderungen der Kategorie mit vollster Zufriedenheit erfüllt, ergibt sich ein Vollausschlag auf der jeweiligen Achse. Die Nichterfüllung einzelner Anforderungen mindert den Ausschlag entsprechend.

Wie stark einzelne Anforderungen in die zugehörige Kategorie einfließen, hängt von der Priorisierung dieser ab. Wurde eine Anforderung mit A bewertet, zählt das Ergebnis zu 100 Prozent. Entsprechend wird der Einfluss bei Priorität B und C auf 50 bzw. 25 Prozent gesenkt. Dies stellt sicher, dass die Nichterfüllung kleiner Anforderungen das Gesamtergebnis nicht zu stark nach unten ziehen. 

Für eine einfache Auswertung reicht die Unterscheidung zwischen Erfüllen (1) und Nichterfüllen (0) der Anforderungen. Somit reicht es die Gewichte der erfüllten Anforderungen pro Kategorie zu kumulieren, den Prozentsatz zu bilden und in die jeweilige Achse einzutragen. Dies hat jedoch den Nachteil, dass gerade bei den qualitativ erhobenen Daten viel Informationsgehalt verloren geht. Wird z.~B. die Lernbarkeit über einer Ordinalskala mit 3 möglichen Werten erhoben (sehr gut, gut, schlecht), geht die Differenzierung zwischen \enquote{sehr gut} und \enquote{gut} bzw. \enquote{gut} und \enquote{schlecht} verloren, je nachdem wo die Akzeptanzschwelle liegt.

Um dies zu verhindern, kann auch eine komplexere Auswertung erfolgen. Diese betrachtet jede erhobene Metrik und stellt einen Erfüllungsgrad pro Anforderung zusammen. Hierzu wird das Ergebnis der Metrik auf einen Wert zwischen 0 und 1 normalisiert. Dies kann bei der zuvor genannten Ordinalskala mit 3 Werten folgende Ergebnisse enthalten:
  
\begin{table}[!h]
	\centering
	\begin{tabular}{ll}
		\textbf{Ergebnisse} & \textbf{Normalisierung}\\
		\hline
		sehr gut 	& 1  	\\
		\hline
		gut			& 0.5	\\
		\hline
		schlecht	& 0  	\\
		\hline
	\end{tabular}
	\caption[Ordinalskala Normalisierung]{Beispiel: Normalisierung einer Ordinalskala mit 3 Werten.}
	\label{Ordinalskala_Normalisierung}
\end{table}

Für quantitativ erhobene Daten kann weiterhin die dyadische Darstellung gewählt werden. Alternativ hierzu kann auch eine Abstufung mittels prozentualer Abweichung zum Zielwert ermittelt werden. Soll z.~B. die Antwortzeit eines ausgelasteten Services unter 10ms im Durchschnitt betragen, könnte folgende Normalisierung gewählt werden:

\begin{table}[!h]
	\centering
	\begin{tabular}{ll}
		\textbf{Ergebnisse} & \textbf{Normalisierung}\\
		\hline
		$\le 10ms$ 		& 1  	\\
		\hline
		$12ms$			& 0.8	\\
		\hline
		$14ms$			& 0.6  	\\
		\hline
		$16ms$			& 0.4  	\\
		\hline
		$18ms$			& 0.2  	\\
		\hline
		$\ge 20ms$		& 0  	\\
		\hline
	\end{tabular}
	\caption[Normalisierung quantitativer Daten]{Beispiel: Normalisierung von quantitativ erhobener Latenzzeit}
	\label{Normalisierung_quant}
\end{table}

Wie die erhobenen Daten normalisiert werden, hängt von den Anforderungen ab und welches Ziel diese verfolgen. Aus diesem Grund ist dies eine Einzelfallentscheidung und obliegt dem Prüfer.

Für den Erfüllungsgrad einer Anforderung können nun die einzelnen normalisierten Ergebnisse kumuliert und der Prozentsatz gebildet werden. Anschließend erfolgt die Multiplikation mit den Gewichten und das Eintragen in die jeweilige Achse analog zur einfachen Darstellung. 

Ein einfaches Beispiel für die Auswertung einer Kategorie findet sich in Bild \ref{AuswertungBeispiel}

\image[AuswertungBeispiel.pdf]{AuswertungBeispiel}{Auswertung Beispiel}{Beispiel für die Auswertung einer Kategorie.}

Die so ausgewerteten und in ein Netzdiagramm eingetragenen Daten bieten einen guten Überblick über die Qualität eines Frameworks. Sie lassen aber auch einen Vergleich mehrerer Frameworks zu, indem verschiedene Ergebnisse in das Diagramm eingetragen werden.

\subsubsection{Resultat präsentieren}



In diesem Schritt werden die Ergebnisse präsentiert und . Dies muss dabei nicht zwangsläufig eine Präsentation sein. Viel mehr geht es um das Aufbereiten der Daten. Dies kann in einem abschließendem Dokument erfolgen. Dabei lassen sich wichtige Anforderungen, die nicht erfüllt wurden hervorheben. Sollten z.~B. Funktionen fehlen, kann bei einem späteren Release des Frameworks die Bewertung verkürzt wiederholt und nur auf diese spezifischen Anforderungen untersucht werden.

Anhand der Ergebnisse kann eine eindeutige und fundierte Aussage über die Akzeptanz des Frameworks getroffen werden. Und das Risiko zur Erfüllung des geforderten Qualitätsziels minimiert sich.

\pagebreak












